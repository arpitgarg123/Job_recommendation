{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# import libraries"
      ],
      "metadata": {
        "id": "AyGu7moNSI3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0IIoVD_SH1K"
      },
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# NLP libraries\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# ML / NLP\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Download required nltk data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Dataset"
      ],
      "metadata": {
        "id": "VMUIdJz5SWse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('all_job_post.csv')"
      ],
      "metadata": {
        "id": "o44tLftySPpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "s69nsco9TZXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select & Clean Required Columns"
      ],
      "metadata": {
        "id": "VZ-d3PFMTmo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['job_title', 'job_description', 'job_skill_set']]"
      ],
      "metadata": {
        "id": "4urgqWMwTdGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "5mrZob7nTs_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing Function (NLP Core)\n",
        "\n",
        "Raw text is messy.\n",
        "NLP models cannot understand raw text.\n",
        "\n",
        "This step:\n",
        "\n",
        "removes noise\n",
        "\n",
        "standardizes text\n",
        "\n",
        "improves similarity accuracy"
      ],
      "metadata": {
        "id": "VM_nNC_4T-2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "j0G80samUH5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
        "    return \" \".join(words)"
      ],
      "metadata": {
        "id": "-5GOqzqQT1W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply Text Cleaning"
      ],
      "metadata": {
        "id": "3vDiO9KoUNuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['job_skill_set'] = df['job_skill_set'].astype(str) # convert the list in str"
      ],
      "metadata": {
        "id": "1vIl23XIc3N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'] = (\n",
        "    df['job_title'] + \" \" +\n",
        "    df['job_skill_set'] + \" \" +\n",
        "    df['job_skill_set']   # repeat to give weight\n",
        ")\n",
        "\n",
        "df['clean_text'] = df['clean_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "pXztYNh9UOsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_text'][0]"
      ],
      "metadata": {
        "id": "84nEoSgoUU61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Text â†’ Numbers (TF-IDF)"
      ],
      "metadata": {
        "id": "UosM0olHUhth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=3000)\n",
        "job_vectors = tfidf.fit_transform(df['clean_text'])"
      ],
      "metadata": {
        "id": "EYnzLUQAUZxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save model"
      ],
      "metadata": {
        "id": "HG9J5yerWyAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(tfidf, \"tfidf.pkl\")\n",
        "joblib.dump(job_vectors, \"job_vectors.pkl\")\n",
        "joblib.dump(df, \"jobs_df.pkl\")"
      ],
      "metadata": {
        "id": "E5kFpEp8WzVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}